{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "# import nltk\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.parse import ViterbiParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"color: #800000;\"><strong>Let's Split the data</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n"
     ]
    }
   ],
   "source": [
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "print(len(train_set))\n",
    "print(len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95506"
      ]
     },
     "execution_count": 802,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['So', 'far', ',', 'Mrs.', 'Hills', 'has', \"n't\", 'deemed', 'any', 'cases']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "95506"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "print(tokens[:10])\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12019\n"
     ]
    }
   ],
   "source": [
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 805,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 806,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.', 'X', 'VERB', 'PRON', 'ADJ', 'NOUN', 'CONJ', 'PRT', 'ADP', 'DET', 'NUM', 'ADV'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 807,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emission Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition Probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 809,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>X</th>\n",
       "      <th>VERB</th>\n",
       "      <th>PRON</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>CONJ</th>\n",
       "      <th>PRT</th>\n",
       "      <th>ADP</th>\n",
       "      <th>DET</th>\n",
       "      <th>NUM</th>\n",
       "      <th>ADV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>0.094346</td>\n",
       "      <td>0.027188</td>\n",
       "      <td>0.089575</td>\n",
       "      <td>0.066979</td>\n",
       "      <td>0.044112</td>\n",
       "      <td>0.221912</td>\n",
       "      <td>0.058246</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>0.090745</td>\n",
       "      <td>0.173569</td>\n",
       "      <td>0.079132</td>\n",
       "      <td>0.051674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <td>0.162891</td>\n",
       "      <td>0.074984</td>\n",
       "      <td>0.204212</td>\n",
       "      <td>0.056477</td>\n",
       "      <td>0.017230</td>\n",
       "      <td>0.061742</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.185386</td>\n",
       "      <td>0.144065</td>\n",
       "      <td>0.054244</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.025686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERB</th>\n",
       "      <td>0.034927</td>\n",
       "      <td>0.218876</td>\n",
       "      <td>0.168504</td>\n",
       "      <td>0.036324</td>\n",
       "      <td>0.064499</td>\n",
       "      <td>0.109826</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.031046</td>\n",
       "      <td>0.091198</td>\n",
       "      <td>0.135051</td>\n",
       "      <td>0.022198</td>\n",
       "      <td>0.081962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRON</th>\n",
       "      <td>0.041319</td>\n",
       "      <td>0.090599</td>\n",
       "      <td>0.486353</td>\n",
       "      <td>0.007961</td>\n",
       "      <td>0.073920</td>\n",
       "      <td>0.208491</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.012130</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>0.009477</td>\n",
       "      <td>0.007582</td>\n",
       "      <td>0.033738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADJ</th>\n",
       "      <td>0.064585</td>\n",
       "      <td>0.020482</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>0.699538</td>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.010737</td>\n",
       "      <td>0.078130</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.020978</td>\n",
       "      <td>0.004790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOUN</th>\n",
       "      <td>0.240351</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.146455</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.263779</td>\n",
       "      <td>0.042727</td>\n",
       "      <td>0.043896</td>\n",
       "      <td>0.177120</td>\n",
       "      <td>0.013268</td>\n",
       "      <td>0.009357</td>\n",
       "      <td>0.017288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONJ</th>\n",
       "      <td>0.033906</td>\n",
       "      <td>0.007896</td>\n",
       "      <td>0.157455</td>\n",
       "      <td>0.058523</td>\n",
       "      <td>0.115653</td>\n",
       "      <td>0.351602</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.053414</td>\n",
       "      <td>0.121691</td>\n",
       "      <td>0.039944</td>\n",
       "      <td>0.055272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRT</th>\n",
       "      <td>0.042979</td>\n",
       "      <td>0.013123</td>\n",
       "      <td>0.403871</td>\n",
       "      <td>0.018045</td>\n",
       "      <td>0.086286</td>\n",
       "      <td>0.245407</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.020669</td>\n",
       "      <td>0.098753</td>\n",
       "      <td>0.056102</td>\n",
       "      <td>0.010499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.039936</td>\n",
       "      <td>0.034704</td>\n",
       "      <td>0.008436</td>\n",
       "      <td>0.069941</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>0.321730</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.017085</td>\n",
       "      <td>0.324826</td>\n",
       "      <td>0.063107</td>\n",
       "      <td>0.013348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DET</th>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.045203</td>\n",
       "      <td>0.039537</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>0.206244</td>\n",
       "      <td>0.637657</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.005545</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.012536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NUM</th>\n",
       "      <td>0.114724</td>\n",
       "      <td>0.207468</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>0.033123</td>\n",
       "      <td>0.358627</td>\n",
       "      <td>0.013249</td>\n",
       "      <td>0.026498</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>0.003312</td>\n",
       "      <td>0.183981</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADV</th>\n",
       "      <td>0.136167</td>\n",
       "      <td>0.023580</td>\n",
       "      <td>0.344404</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>0.129857</td>\n",
       "      <td>0.030555</td>\n",
       "      <td>0.006974</td>\n",
       "      <td>0.014281</td>\n",
       "      <td>0.119562</td>\n",
       "      <td>0.068748</td>\n",
       "      <td>0.030887</td>\n",
       "      <td>0.079376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             .         X      VERB      PRON       ADJ      NOUN      CONJ  \\\n",
       ".     0.094346  0.027188  0.089575  0.066979  0.044112  0.221912  0.058246   \n",
       "X     0.162891  0.074984  0.204212  0.056477  0.017230  0.061742  0.010211   \n",
       "VERB  0.034927  0.218876  0.168504  0.036324  0.064499  0.109826  0.005588   \n",
       "PRON  0.041319  0.090599  0.486353  0.007961  0.073920  0.208491  0.005307   \n",
       "ADJ   0.064585  0.020482  0.012223  0.000661  0.065907  0.699538  0.016848   \n",
       "NOUN  0.240351  0.029094  0.146455  0.004715  0.011952  0.263779  0.042727   \n",
       "CONJ  0.033906  0.007896  0.157455  0.058523  0.115653  0.351602  0.000464   \n",
       "PRT   0.042979  0.013123  0.403871  0.018045  0.086286  0.245407  0.002297   \n",
       "ADP   0.039936  0.034704  0.008436  0.069941  0.104645  0.321730  0.000854   \n",
       "DET   0.017358  0.045203  0.039537  0.003616  0.206244  0.637657  0.000482   \n",
       "NUM   0.114724  0.207468  0.018067  0.001506  0.033123  0.358627  0.013249   \n",
       "ADV   0.136167  0.023580  0.344404  0.015609  0.129857  0.030555  0.006974   \n",
       "\n",
       "           PRT       ADP       DET       NUM       ADV  \n",
       ".     0.002431  0.090745  0.173569  0.079132  0.051674  \n",
       "X     0.185386  0.144065  0.054244  0.002872  0.025686  \n",
       "VERB  0.031046  0.091198  0.135051  0.022198  0.081962  \n",
       "PRON  0.012130  0.023124  0.009477  0.007582  0.033738  \n",
       "ADJ   0.010737  0.078130  0.005121  0.020978  0.004790  \n",
       "NOUN  0.043896  0.177120  0.013268  0.009357  0.017288  \n",
       "CONJ  0.004180  0.053414  0.121691  0.039944  0.055272  \n",
       "PRT   0.001969  0.020669  0.098753  0.056102  0.010499  \n",
       "ADP   0.001388  0.017085  0.324826  0.063107  0.013348  \n",
       "DET   0.000241  0.009523  0.005545  0.022059  0.012536  \n",
       "NUM   0.026498  0.036435  0.003312  0.183981  0.003011  \n",
       "ADV   0.014281  0.119562  0.068748  0.030887  0.079376  "
      ]
     },
     "execution_count": 812,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 813,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95506"
      ]
     },
     "execution_count": 813,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><span style=\"color: #ff0000;\"><strong>Build the Vanilla Viterbi Algorithm</strong></span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 814,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"color: #ff0000;\"><strong>Check on 10 randomly selected sentences</strong></span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Some',\n",
       " 'Democrats',\n",
       " 'in',\n",
       " 'Congress',\n",
       " 'are',\n",
       " 'warning',\n",
       " 'that',\n",
       " 'a',\n",
       " 'complicated',\n",
       " 'new']"
      ]
     },
     "execution_count": 815,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's test our Viterbi algorithm on a few sample sentences of test dataset\n",
    "random.seed(1234)\n",
    "\n",
    "# choose random 5 sents\n",
    "rndom = [random.randint(1,len(test_set)) for x in range(10)]\n",
    "\n",
    "# list of sents\n",
    "test_run = [test_set[i] for i in rndom]\n",
    "\n",
    "# list of tagged words\n",
    "test_run_base = [tup for sent in test_run for tup in sent]\n",
    "\n",
    "# list of untagged words\n",
    "test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n",
    "# test_tagged_words\n",
    "# test_run\n",
    "test_tagged_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_main = [tup[0] for sent in test_set for tup in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagging the test sentences\n",
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_tagged_words)\n",
    "end = time.time()\n",
    "difference = end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 818,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Some', 'DET'), ('Democrats', 'NOUN'), ('in', 'ADP'), ('Congress', 'NOUN'), ('are', 'VERB'), ('warning', 'VERB'), ('that', 'ADP'), ('a', 'DET'), ('complicated', 'ADJ'), ('new', 'ADJ')]\n"
     ]
    }
   ],
   "source": [
    "print(tagged_seq[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: #339966;\">Accuracy for the Vanilla viterbi Algorithm</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 819,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.58232931726907"
      ]
     },
     "execution_count": 819,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy1 = len(check)/len(tagged_seq)\n",
    "accuracy1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color: #ff0000;\">Incorrectly tagged words for vanilla algorithm</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_seq\n",
    "vanilla_list = incorrect_tagged_cases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_words = []\n",
    "right_words = []\n",
    "for i, j in enumerate(zip(tagged_seq, test_run_base)):\n",
    "#     print([test_run_base[i-1],j])\n",
    "    if(j[0]!=j[1]):\n",
    "        wrong_words.append(j[0])\n",
    "        right_words.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('closer', 'ADJ'), ('achieving', '.'), ('downward', 'ADV'), ('Left', '.'), ('more', 'ADJ'), ('sound', 'NOUN'), ('altering', '.'), ('Peoria', '.'), ('71,309', '.'), ('Borough', '.'), ('up', 'ADV')]\n"
     ]
    }
   ],
   "source": [
    "print(wrong_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 824,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('closer', 'ADV'), ('achieving', 'VERB'), ('downward', 'ADJ'), ('Left', 'VERB'), ('more', 'ADV'), ('sound', 'VERB'), ('altering', 'VERB'), ('Peoria', 'NOUN'), ('71,309', 'NUM'), ('Borough', 'NOUN'), ('up', 'PRT')]\n"
     ]
    }
   ],
   "source": [
    "print(right_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><span style=\"color: #003366;\">Testing on the test file</span></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Testing on the test file\n",
    "file = open(\"Test_sentences.txt\", \"r\") \n",
    "words=[]\n",
    "for line in file:\n",
    "    words.append(word_tokenize(line.rstrip()))\n",
    "word_list = [word for sent in words for word in sent] #This will remain for all our future tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test1 = Viterbi(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Android', '.'),\n",
       " ('is', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('mobile', 'ADJ'),\n",
       " ('operating', 'NOUN'),\n",
       " ('system', 'NOUN'),\n",
       " ('developed', 'VERB'),\n",
       " ('by', 'ADP'),\n",
       " ('Google', '.'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 827,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_test1[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rule 1: Instead of taking the emission probability as 0, we will try to put 0.00001 as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi_modified(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = (word_given_tag(words[key], tag)[0])/(word_given_tag(words[key], tag)[1]) or 0.00001\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 829,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_seq = Viterbi_modified(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.18875502008032"
      ]
     },
     "execution_count": 830,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = [i for i, j in zip(tagged_seq, test_run_base) if i == j]\n",
    "accuracy2 = len(check)/len(tagged_seq)\n",
    "accuracy2*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "Viterbi_modified_list = incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('coming', 'VERB'), (('closer', 'ADJ'), ('closer', 'ADV'))],\n",
       " [('the', 'DET'), (('stated', 'NOUN'), ('stated', 'VERB'))],\n",
       " [('some', 'DET'), (('downward', 'NOUN'), ('downward', 'ADJ'))],\n",
       " [('and', 'CONJ'), (('more', 'ADJ'), ('more', 'ADV'))],\n",
       " [('bells', 'NOUN'), (('sound', 'NOUN'), ('sound', 'VERB'))],\n",
       " [('$', '.'), (('71,309', 'NOUN'), ('71,309', 'NUM'))],\n",
       " [('ran', 'VERB'), (('up', 'ADV'), ('up', 'PRT'))]]"
      ]
     },
     "execution_count": 832,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color: #ff0000;\">During the last run, we got the accuracy of&nbsp;95.3%</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_words = []\n",
    "right_words = []\n",
    "for i, j in enumerate(zip(tagged_seq, test_run_base)):\n",
    "#     print([test_run_base[i-1],j])\n",
    "    if(j[0]!=j[1]):\n",
    "        wrong_words.append(j[0])\n",
    "        right_words.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('closer', 'ADJ'), ('stated', 'NOUN'), ('downward', 'NOUN'), ('more', 'ADJ'), ('sound', 'NOUN'), ('71,309', 'NOUN'), ('up', 'ADV')]\n"
     ]
    }
   ],
   "source": [
    "print(wrong_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('closer', 'ADV'), ('stated', 'VERB'), ('downward', 'ADJ'), ('more', 'ADV'), ('sound', 'VERB'), ('71,309', 'NUM'), ('up', 'PRT')]\n"
     ]
    }
   ],
   "source": [
    "print(right_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><strong><span style=\"color: #339966;\">Let's look into preventing misclassification of numbers and further optimisations</span></strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the list of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arrest', 'Peoria', 'cheapest', 'Blue', 'healing', 'maze', 'Power', 'Spence', 'how-to', '*T*-216']\n"
     ]
    }
   ],
   "source": [
    "#Unknown words, getting the list\n",
    "list1 = [i[0] for i in train_tagged_words]\n",
    "list2 = test_main\n",
    "unknown = list((set(list2).difference(set(list1))))\n",
    "print(unknown[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = [\n",
    "    (r'.*ing$', 'VERB'),              # gerund\n",
    "    (r'.*ed$', 'VERB'),               # past tense\n",
    "    (r'.*es$', 'VERB'),               # 3rd singular present\n",
    "    (r'.*ould$', 'VERB'),              # modals\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'), # cardinal numbers\n",
    "    (r'.*', 'NOUN')                    # nouns\n",
    "]\n",
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "bigram = nltk.BigramTagger(train_set,backoff=regexp_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><strong><span style=\"color: #339966;\">Testing out our bigram tagger</span></strong></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DET'"
      ]
     },
     "execution_count": 838,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list1 = test_tagged_words\n",
    "list1.append(test_tagged_words[0])\n",
    "bigram.tag(list(list1))[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_test(words,unknown=unknown, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    prob = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = []\n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:                \n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "            # compute emission and state probabilities\n",
    "            emission_p = (word_given_tag(words[key], tag)[0])/(word_given_tag(words[key], tag)[1]) or 0.00001     \n",
    "            if words[key] in unknown:\n",
    "                state_probability = transition_p\n",
    "                flag=True\n",
    "#                 print(words[key],transition_p)\n",
    "            else:\n",
    "                flag=False\n",
    "                state_probability = emission_p * transition_p\n",
    "            p.append(state_probability)\n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        list1 = []\n",
    "        if float(pmax) < float(0.00001):\n",
    "#             list1=[words[key-1],words[key]]\n",
    "            state.append(bigram.tag(words[key])[0][1])\n",
    "#             print(state)\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "        prob.append(pmax)\n",
    "#     return list(zip(list(zip(words, state)), prob))\n",
    "    return list(zip(words, state))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy for the random 10 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = Viterbi_test(test_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(right_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.39999999999999"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check = [i for i, j in zip(tagged_words, test_run_base) if i == j]\n",
    "accuracy3 = len(check)/len(tagged_words)\n",
    "accuracy3*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "Viterbi_test_list = incorrect_tagged_cases[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_words = []\n",
    "right_words = []\n",
    "for i, j in enumerate(zip(tagged_words, test_run_base)):\n",
    "#     print([test_run_base[i-1],j])\n",
    "    if(j[0][0]!=j[1]):\n",
    "        wrong_words.append(j[0])\n",
    "        right_words.append(j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Some', 'DET'),\n",
       " ('Democrats', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Congress', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('warning', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('complicated', 'ADJ'),\n",
       " ('new', 'ADJ')]"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Some', 'DET'),\n",
       " ('Democrats', 'NOUN'),\n",
       " ('in', 'ADP'),\n",
       " ('Congress', 'NOUN'),\n",
       " ('are', 'VERB'),\n",
       " ('warning', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('complicated', 'ADJ'),\n",
       " ('new', 'ADJ')]"
      ]
     },
     "execution_count": 849,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><span style=\"background-color: #ffffff; color: #ff0000;\"><strong>Third modification, directly sending the unknown words to the tagger</strong></span></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Viterbi_mod2(words,unknown_words=unknown, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            \n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1] or 0.00001\n",
    "\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "#         if (re.search(r'^-?[0-9]+(.[0-9]+)?$',word)!=None):\n",
    "#             state.append('NUM')\n",
    "        if words[key] in unknown_words:\n",
    "#             list1=[words[key-1],words[key]]\n",
    "            state.append(bigram.tag(words[key])[0][1])\n",
    "        else:\n",
    "            state_max = T[p.index(pmax)]\n",
    "            state.append(state_max)\n",
    "   \n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.39999999999999"
      ]
     },
     "execution_count": 851,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_seq = Viterbi_mod2(test_tagged_words)\n",
    "check = [i for i, j in zip(tagged_words, test_run_base) if i == j]\n",
    "accuracy4 = len(check)/len(tagged_words)\n",
    "accuracy4*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_tagged_cases = [[test_run_base[i-1],j] for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]\n",
    "Viterbi_mod2_list = incorrect_tagged_cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing sample test file output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 853,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_test1 = Viterbi(word_list)\n",
    "tagged_test2 = Viterbi_test(word_list)\n",
    "tagged_test3 = Viterbi_modified(word_list)\n",
    "tagged_test4 = Viterbi_mod2(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can see that viterbi_modified and viterbi mod2 are the best models that we have here, however viterbi_modified gives us the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "<h4><span style=\"color: #000080;\">List of Modifications:</span></h4>\n",
    "<ul>\n",
    "<li><strong><span style=\"color: #008000;\">Viterbi_Modified - Changed the emission probability directly to 0.00001 instead of 0 for particular cases wehen the emisssion probability will be 0 for the unknown words.</span></strong></li>\n",
    "<li><strong><span style=\"color: #008000;\">Viterbi_test - If the max probability is very low, use the Bigram and the rule based tagger</span></strong></li>\n",
    "<li><strong><span style=\"color: #008000;\">Viterbi_mod2 - Send the unknown words directly to the bigram and rule based tagger.</span></strong></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1 = pd.DataFrame(tagged_test1,columns=['word','vanilla_tag'])\n",
    "dt2 = pd.DataFrame(tagged_test3,columns=['word','modified_tag'])\n",
    "dt3 = pd.DataFrame(tagged_test2,columns=['word','test_tag'])\n",
    "dt4 = pd.DataFrame(tagged_test4,columns=['word','mod2_tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt5= pd.merge(dt1,dt2,on='word')\n",
    "dt6 = pd.merge(dt1,dt3,on='word')\n",
    "dt7 = pd.merge(dt1,dt4,on='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vanilla_tag</th>\n",
       "      <th>modified_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>OS</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>worldwide</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>smartphones</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2011</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2013</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2015</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>interact</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>messages</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>tweets</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>entering</td>\n",
       "      <td>VERB</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>domineering</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>personality</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2018</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>21st</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>tournament</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>contested</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>cheapest</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>trips</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>arriving</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NASA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>invited</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>ICESAT-2</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Satellite</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word vanilla_tag modified_tag\n",
       "0        Android           .         NOUN\n",
       "1        Android           .         NOUN\n",
       "2        Android           .         NOUN\n",
       "3        Android           .         NOUN\n",
       "41        Google           .          DET\n",
       "42        Google           .         NOUN\n",
       "43        Google           .            X\n",
       "44        Google           .          DET\n",
       "45        Google           .         NOUN\n",
       "46        Google           .            X\n",
       "47        Google           .          DET\n",
       "48        Google           .         NOUN\n",
       "49        Google           .            X\n",
       "240           OS           .         NOUN\n",
       "241    worldwide           .         NOUN\n",
       "251  smartphones           .          DET\n",
       "256         2011           .          DET\n",
       "307         2013           .          DET\n",
       "308      Twitter           .         NOUN\n",
       "309      Twitter           .         VERB\n",
       "310      Twitter           .         NOUN\n",
       "311      Twitter           .         NOUN\n",
       "312      Twitter           .         VERB\n",
       "313      Twitter           .         NOUN\n",
       "314      Twitter           .         NOUN\n",
       "315      Twitter           .         VERB\n",
       "316      Twitter           .         NOUN\n",
       "344         2015           .          DET\n",
       "345         that         DET          ADP\n",
       "346         that         DET          ADP\n",
       "..           ...         ...          ...\n",
       "407     interact           .         NOUN\n",
       "409     messages           .          DET\n",
       "412       tweets           .          DET\n",
       "414     entering        VERB          DET\n",
       "423  domineering           .         NOUN\n",
       "426  personality           .         NOUN\n",
       "428         2018           .         NOUN\n",
       "429         FIFA           .         NOUN\n",
       "430         FIFA           .         NOUN\n",
       "431         FIFA           .         NOUN\n",
       "432         FIFA           .         NOUN\n",
       "442          Cup           .         NOUN\n",
       "443          Cup           .         NOUN\n",
       "444          Cup           .         NOUN\n",
       "445          Cup           .         NOUN\n",
       "446          Cup           .         NOUN\n",
       "447          Cup           .         NOUN\n",
       "448          Cup           .         NOUN\n",
       "449          Cup           .         NOUN\n",
       "450          Cup           .         NOUN\n",
       "451         21st           .         NOUN\n",
       "454   tournament           .         NOUN\n",
       "455    contested           .         NOUN\n",
       "483     cheapest           .         NOUN\n",
       "485        trips           .         NOUN\n",
       "515     arriving           .         NOUN\n",
       "518         NASA           .         NOUN\n",
       "519      invited           .         NOUN\n",
       "523     ICESAT-2           .          DET\n",
       "524    Satellite           .         NOUN\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 856,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5[dt5['vanilla_tag']!=dt5['modified_tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "<h4><span style=\"color: #ff0000;\"><span style=\"color: #000080;\">From the above dataframe:</span></span></h4>\n",
    "<ul>\n",
    "<li><span style=\"color: #ff0000;\"><span style=\"color: #008000;\"><strong>Nouns are modified much better.</strong></span></span></li>\n",
    "<li><span style=\"color: #ff0000;\"><span style=\"color: #008000;\"><strong>63 changes are listed down in the data frame that were incorrectly determined by the vanilla algorithm</strong></span></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 857,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vanilla_tag</th>\n",
       "      <th>test_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>OS</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>worldwide</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>smartphones</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2011</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2013</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2015</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>interact</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>messages</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>tweets</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>entering</td>\n",
       "      <td>VERB</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>domineering</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>personality</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2018</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>21st</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>tournament</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>contested</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>cheapest</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>trips</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>arriving</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NASA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>invited</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>ICESAT-2</td>\n",
       "      <td>.</td>\n",
       "      <td>PRON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Satellite</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word vanilla_tag test_tag\n",
       "0        Android           .      DET\n",
       "1        Android           .      DET\n",
       "2        Android           .      DET\n",
       "3        Android           .      DET\n",
       "41        Google           .     NOUN\n",
       "42        Google           .     NOUN\n",
       "43        Google           .     NOUN\n",
       "44        Google           .     NOUN\n",
       "45        Google           .     NOUN\n",
       "46        Google           .     NOUN\n",
       "47        Google           .     NOUN\n",
       "48        Google           .     NOUN\n",
       "49        Google           .     NOUN\n",
       "240           OS           .     NOUN\n",
       "241    worldwide           .     NOUN\n",
       "251  smartphones           .     NOUN\n",
       "256         2011           .        X\n",
       "307         2013           .        X\n",
       "308      Twitter           .     NOUN\n",
       "309      Twitter           .     NOUN\n",
       "310      Twitter           .     NOUN\n",
       "311      Twitter           .     NOUN\n",
       "312      Twitter           .     NOUN\n",
       "313      Twitter           .     NOUN\n",
       "314      Twitter           .     NOUN\n",
       "315      Twitter           .     NOUN\n",
       "316      Twitter           .     NOUN\n",
       "344         2015           .        X\n",
       "345         that         DET      ADP\n",
       "346         that         DET      ADP\n",
       "..           ...         ...      ...\n",
       "407     interact           .     NOUN\n",
       "409     messages           .     NOUN\n",
       "412       tweets           .     NOUN\n",
       "414     entering        VERB     NOUN\n",
       "423  domineering           .     NOUN\n",
       "426  personality           .     NOUN\n",
       "428         2018           .        X\n",
       "429         FIFA           .     NOUN\n",
       "430         FIFA           .     NOUN\n",
       "431         FIFA           .     NOUN\n",
       "432         FIFA           .     NOUN\n",
       "442          Cup           .     NOUN\n",
       "443          Cup           .     NOUN\n",
       "444          Cup           .     NOUN\n",
       "445          Cup           .     NOUN\n",
       "446          Cup           .     NOUN\n",
       "447          Cup           .     NOUN\n",
       "448          Cup           .     NOUN\n",
       "449          Cup           .     NOUN\n",
       "450          Cup           .     NOUN\n",
       "451         21st           .        X\n",
       "454   tournament           .     NOUN\n",
       "455    contested           .     NOUN\n",
       "483     cheapest           .     NOUN\n",
       "485        trips           .     NOUN\n",
       "515     arriving           .        X\n",
       "518         NASA           .     NOUN\n",
       "519      invited           .     NOUN\n",
       "523     ICESAT-2           .     PRON\n",
       "524    Satellite           .     NOUN\n",
       "\n",
       "[64 rows x 3 columns]"
      ]
     },
     "execution_count": 857,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt6[dt6['vanilla_tag']!=dt6['test_tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>\n",
    "<h4><span style=\"color: #ff0000;\"><span style=\"color: #000080;\">From the above dataframe:</span></span></h4>\n",
    "<ul>\n",
    "<li><span style=\"color: #ff0000;\"><span style=\"color: #008000;\"><strong>Nouns are modified much better.</strong></span></span></li>\n",
    "<li><span style=\"color: #ff0000;\"><span style=\"color: #008000;\"><strong>Although accuracy is lowwe than the first modification, the performance is better because we have tagged more words correctly.</strong></span></span></li>\n",
    "<li><span style=\"color: #ff0000;\"><span style=\"color: #008000;\"><strong>64 changes are listed down in the data frame that were incorrectly determined by the vanilla algorithm.</strong></span></span></li>\n",
    "</ul>\n",
    "</li>\n",
    "</ul>\n",
    "<h1><span style=\"color: #ff0000;\">Viterbi_test is the best algorithm</span></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 858,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>vanilla_tag</th>\n",
       "      <th>mod2_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Android</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Google</td>\n",
       "      <td>.</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>OS</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>worldwide</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>smartphones</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2011</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>2013</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>2015</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>that</td>\n",
       "      <td>DET</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>interact</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>messages</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>tweets</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>entering</td>\n",
       "      <td>VERB</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>domineering</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>personality</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>2018</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>FIFA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>Cup</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>21st</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>tournament</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>contested</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>cheapest</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>trips</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>arriving</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>NASA</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>invited</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>ICESAT-2</td>\n",
       "      <td>.</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Satellite</td>\n",
       "      <td>.</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word vanilla_tag mod2_tag\n",
       "0        Android           .     NOUN\n",
       "1        Android           .     NOUN\n",
       "2        Android           .     NOUN\n",
       "3        Android           .     NOUN\n",
       "41        Google           .      DET\n",
       "42        Google           .     NOUN\n",
       "43        Google           .        X\n",
       "44        Google           .      DET\n",
       "45        Google           .     NOUN\n",
       "46        Google           .        X\n",
       "47        Google           .      DET\n",
       "48        Google           .     NOUN\n",
       "49        Google           .        X\n",
       "240           OS           .     NOUN\n",
       "241    worldwide           .     NOUN\n",
       "251  smartphones           .      DET\n",
       "256         2011           .      DET\n",
       "307         2013           .      DET\n",
       "308      Twitter           .     NOUN\n",
       "309      Twitter           .     VERB\n",
       "310      Twitter           .     NOUN\n",
       "311      Twitter           .     NOUN\n",
       "312      Twitter           .     VERB\n",
       "313      Twitter           .     NOUN\n",
       "314      Twitter           .     NOUN\n",
       "315      Twitter           .     VERB\n",
       "316      Twitter           .     NOUN\n",
       "344         2015           .      DET\n",
       "345         that         DET      ADP\n",
       "346         that         DET      ADP\n",
       "..           ...         ...      ...\n",
       "407     interact           .     NOUN\n",
       "409     messages           .      DET\n",
       "412       tweets           .      DET\n",
       "414     entering        VERB      DET\n",
       "423  domineering           .     NOUN\n",
       "426  personality           .     NOUN\n",
       "428         2018           .     NOUN\n",
       "429         FIFA           .     NOUN\n",
       "430         FIFA           .     NOUN\n",
       "431         FIFA           .     NOUN\n",
       "432         FIFA           .     NOUN\n",
       "442          Cup           .     NOUN\n",
       "443          Cup           .     NOUN\n",
       "444          Cup           .     NOUN\n",
       "445          Cup           .     NOUN\n",
       "446          Cup           .     NOUN\n",
       "447          Cup           .     NOUN\n",
       "448          Cup           .     NOUN\n",
       "449          Cup           .     NOUN\n",
       "450          Cup           .     NOUN\n",
       "451         21st           .     NOUN\n",
       "454   tournament           .     NOUN\n",
       "455    contested           .     NOUN\n",
       "483     cheapest           .     NOUN\n",
       "485        trips           .     NOUN\n",
       "515     arriving           .     NOUN\n",
       "518         NASA           .     NOUN\n",
       "519      invited           .     NOUN\n",
       "523     ICESAT-2           .      DET\n",
       "524    Satellite           .     NOUN\n",
       "\n",
       "[63 rows x 3 columns]"
      ]
     },
     "execution_count": 858,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt7[dt7['vanilla_tag']!=dt7['mod2_tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
